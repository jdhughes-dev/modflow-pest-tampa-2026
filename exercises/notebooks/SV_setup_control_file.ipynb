{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Build the pest interface and generate the Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import shutil\n",
    "import flopy\n",
    "import pandas as pd\n",
    "import pyemu\n",
    "import helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are slow as...\n",
    "# safe_org_d = os.path.join(\"..\", \"models\", \"synthetic-valley-working-monthly\")\n",
    "# safe_org_d = os.path.join(\"..\", \"models\", \"synthetic-valley-working_advanced-monthly\")\n",
    "\n",
    "\n",
    "safe_org_d = os.path.join(\"..\", \"models\", \"synthetic-valley-working-annual\")\n",
    "# safe_org_d = os.path.join(\"..\", \"models\", \"synthetic-valley-working-advanced-annual\")\n",
    "assert os.path.exists(safe_org_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "Make a copy of the safe set of model files and run mf6 in that directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_d = \"temp\"\n",
    "if os.path.exists(tmp_d):\n",
    "    shutil.rmtree(tmp_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = flopy.mf6.MFSimulation.load(sim_ws=safe_org_d)\n",
    "sim.set_sim_path(tmp_d)\n",
    "gwf = sim.get_model()\n",
    "gwf.set_all_data_external(external_data_folder=\".\")\n",
    "sim.write_simulation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.run_simulation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.remove_package(\"ims\")\n",
    "ims = flopy.mf6.ModflowIms(\n",
    "    sim,\n",
    "    print_option=\"summary\",\n",
    "    complexity=\"complex\",\n",
    "    under_relaxation=None,\n",
    "    linear_acceleration=\"bicgstab\",\n",
    "    outer_maximum=500,\n",
    "    inner_maximum=100,\n",
    "    outer_dvclose=1e-3,\n",
    "    inner_dvclose=1e-3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.continue_ = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.write_simulation()\n",
    "sim.run_simulation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "Make a `PstFrom` instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = pyemu.utils.PstFrom(\n",
    "    tmp_d,\n",
    "    \"model_and_pest_files\",\n",
    "    remove_existing=True,\n",
    "    spatial_reference=gwf.modelgrid,\n",
    "    zero_based=False,\n",
    "    start_datetime=gwf.start_datetime,\n",
    "    echo=False,\n",
    "    chunk_len=1000000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "We are using a model-post-processing function clean up and process csv output files.  We need to tell `PstFrom` to run that function after mf6 runs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "helpers.process_csv_files(model_ws=pf.new_d)\n",
    "pf.add_py_function(\"helpers.py\", \"process_csv_files()\", is_pre_cmd=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "Tell `PstFrom` to run mf6 as the \"model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.mod_sys_cmds.append(\"mf6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "Add the first set of model outputs as \"observations\" in the pest interface: \"swgw-longterm-means.csv\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(pf.new_d, \"swgw-longterm-means.csv\"), index_col=0)\n",
    "df = pf.add_observations(\n",
    "    \"swgw-longterm-means.csv\",\n",
    "    index_cols=\"quantity\",\n",
    "    prefix=\"forecasts\",\n",
    "    obsgp=\"forecasts\",\n",
    "    ofile_sep=\",\",\n",
    ")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "Now lets gather up all the output timeseries csv file we want to have as observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_csv_files = [\n",
    "    f for f in os.listdir(pf.new_d) if f.startswith(\"sv.gwf\") and f.endswith(\".csv\")\n",
    "]\n",
    "obs_csv_files.extend(\n",
    "    [f for f in os.listdir(pf.new_d) if f.startswith(\"sv.lake\") and f.endswith(\".csv\")]\n",
    ")\n",
    "obs_csv_files.extend(\n",
    "    [f for f in os.listdir(pf.new_d) if f.startswith(\"sv.riv\") and f.endswith(\".csv\")]\n",
    ")\n",
    "obs_csv_files.extend(\n",
    "    [f for f in os.listdir(pf.new_d) if f.startswith(\"sv.sfr\") and f.endswith(\".csv\")]\n",
    ")\n",
    "obs_csv_files.extend(\n",
    "    [\n",
    "        f\n",
    "        for f in os.listdir(pf.new_d)\n",
    "        if f.startswith(\"sv-budget\") and f.endswith(\".csv\")\n",
    "    ]\n",
    ")\n",
    "obs_csv_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "Loop over them and add each one to the interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "for obs_csv_file in obs_csv_files:\n",
    "    print(obs_csv_file)\n",
    "    prefix = obs_csv_file.replace(\".\", \"-\")\n",
    "    df = pd.read_csv(os.path.join(pf.new_d, obs_csv_file), index_col=0)\n",
    "    odf = pf.add_observations(\n",
    "        obs_csv_file,\n",
    "        index_cols=\"datetime\",\n",
    "        use_cols=df.columns.to_list(),\n",
    "        prefix=prefix,\n",
    "        ofile_sep=\",\",\n",
    "    )\n",
    "    print(odf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "Now some parameters.  Start with hk - the ole classic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_files = [f for f in os.listdir(pf.new_d) if f.startswith(\"sv.npf_k_layer\")]\n",
    "assert len(k_files) == gwf.dis.nlay.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_files.sort()\n",
    "k_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "We need to define some spatial correlation functions/information for the pilot points (for both interpolation from pilot points to the grid and also for the Prior covariance).  We will use a different correlation function for each property type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_v_k = pyemu.geostats.ExpVario(contribution=1.0, a=10000)\n",
    "pp_geostruct_k = pyemu.geostats.GeoStruct(variograms=pp_v_k, transform=\"log\")\n",
    "pp_v_k33 = pyemu.geostats.ExpVario(contribution=1.0, a=15000)\n",
    "pp_geostruct_k33 = pyemu.geostats.GeoStruct(variograms=pp_v_k33, transform=\"log\")\n",
    "pp_v_ss = pyemu.geostats.ExpVario(contribution=1.0, a=5000)\n",
    "pp_geostruct_ss = pyemu.geostats.GeoStruct(variograms=pp_v_ss, transform=\"log\")\n",
    "pp_v_sy = pyemu.geostats.ExpVario(contribution=1.0, a=2000)\n",
    "pp_geostruct_sy = pyemu.geostats.GeoStruct(variograms=pp_v_sy, transform=\"none\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "We will treat HK in layer 1 and 2 as same quantity - they will share pilot point multiplier parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pf.add_parameters(\n",
    "    k_files[:2],\n",
    "    par_type=\"pilotpoints\",\n",
    "    pp_options={\"pp_space\": 3},\n",
    "    lower_bound=0.1,\n",
    "    upper_bound=10.0,\n",
    "    geostruct=pp_geostruct_k,\n",
    "    par_name_base=\"hk-pp-wt\",\n",
    "    pargp=\"hk-pp-wt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "Since the pilot points are designed to accomodate spatial heterogeneity, let's also include a layer-constant parameter to help sample a wider range of HK values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pf.add_parameters(\n",
    "    k_files[:2],\n",
    "    par_type=\"constant\",\n",
    "    lower_bound=0.1,\n",
    "    upper_bound=10.0,\n",
    "    par_name_base=\"hk-cn-wt\",\n",
    "    pargp=\"hk-cn-wt\",\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "Do the same for HK in layer 3 and HK in layers 4 and 5 together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pf.add_parameters(\n",
    "#     k_files[2],\n",
    "#     par_type=\"pilotpoints\",\n",
    "#     pp_options={\"pp_space\": 3},\n",
    "#     lower_bound=0.1,\n",
    "#     upper_bound=10.0,\n",
    "#     geostruct=pp_geostruct_k,\n",
    "#     par_name_base=\"hk-pp-conf\",\n",
    "#     pargp=\"hk-pp-conf\",\n",
    "# )\n",
    "# df = pf.add_parameters(\n",
    "#     k_files[2],\n",
    "#     par_type=\"constant\",\n",
    "#     lower_bound=0.10,\n",
    "#     upper_bound=1.0,\n",
    "#     par_name_base=\"hk-cn-conf\",\n",
    "#     pargp=\"hk-cn-conf\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pf.add_parameters(\n",
    "    k_files[3:],\n",
    "    par_type=\"pilotpoints\",\n",
    "    pp_options={\"pp_space\": 3},\n",
    "    lower_bound=0.1,\n",
    "    upper_bound=10.0,\n",
    "    geostruct=pp_geostruct_k,\n",
    "    par_name_base=\"hk-pp-aq\",\n",
    "    pargp=\"hk-pp-aq\",\n",
    ")\n",
    "df = pf.add_parameters(\n",
    "    k_files[3:],\n",
    "    par_type=\"constant\",\n",
    "    lower_bound=0.10,\n",
    "    upper_bound=1.0,\n",
    "    par_name_base=\"hk-cn-aq\",\n",
    "    pargp=\"hk-cn-aq\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "To let us see what the actual HK array that mf6 sees, let's add that array as a set of observatitons also:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k_file in [k_files[0], k_files[-1]]:\n",
    "    print(k_file)\n",
    "    pf.add_observations(\n",
    "        k_file,\n",
    "        obsgp=k_file.split(\".\")[1].replace(\"_\", \"-\"),\n",
    "        prefix=k_file.split(\".\")[1].replace(\"_\", \"-\"),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "Setup a similar scheme of parameters to VK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "k33_files = [f for f in os.listdir(pf.new_d) if f.startswith(\"sv.npf_k33_layer\")]\n",
    "assert len(k_files) == gwf.dis.nlay.data\n",
    "k33_files.sort()\n",
    "\n",
    "# df = pf.add_parameters(\n",
    "#     k33_files[:2],\n",
    "#     par_type=\"pilotpoints\",\n",
    "#     pp_options={\"pp_space\": 3},\n",
    "#     lower_bound=0.1,\n",
    "#     upper_bound=10.0,\n",
    "#     geostruct=pp_geostruct_k33,\n",
    "#     par_name_base=\"k33-pp-wt\",\n",
    "#     pargp=\"k33-pp-wt\",\n",
    "# )\n",
    "# df = pf.add_parameters(\n",
    "#     k33_files[:2],\n",
    "#     par_type=\"constant\",\n",
    "#     lower_bound=0.1,\n",
    "#     upper_bound=10.0,\n",
    "#     par_name_base=\"k33-cn-wt\",\n",
    "#     pargp=\"k33-cn-wt\",\n",
    "# )\n",
    "\n",
    "# pf.add_observations(\n",
    "#     k33_files[0],\n",
    "#     obsgp=k33_files[0].split(\".\")[1].replace(\"_\", \"-\"),\n",
    "#     prefix=k33_files[0].split(\".\")[1].replace(\"_\", \"-\"),\n",
    "# )\n",
    "\n",
    "df = pf.add_parameters(\n",
    "    k33_files[2],\n",
    "    par_type=\"pilotpoints\",\n",
    "    pp_options={\"pp_space\": 3},\n",
    "    lower_bound=0.01,\n",
    "    upper_bound=100.0,\n",
    "    geostruct=pp_geostruct_k33,\n",
    "    par_name_base=\"k33-pp-conf\",\n",
    "    pargp=\"k33-pp-conf\",\n",
    ")\n",
    "df = pf.add_parameters(\n",
    "    k33_files[2],\n",
    "    par_type=\"constant\",\n",
    "    lower_bound=0.1,\n",
    "    upper_bound=10.0,\n",
    "    par_name_base=\"k33-cn-conf\",\n",
    "    pargp=\"k33-cn-conf\",\n",
    ")\n",
    "\n",
    "pf.add_observations(\n",
    "    k33_files[2],\n",
    "    obsgp=k33_files[2].split(\".\")[1].replace(\"_\", \"-\"),\n",
    "    prefix=k33_files[2].split(\".\")[1].replace(\"_\", \"-\"),\n",
    ")\n",
    "\n",
    "\n",
    "# df = pf.add_parameters(\n",
    "#     k33_files[3:],\n",
    "#     par_type=\"pilotpoints\",\n",
    "#     pp_options={\"pp_space\": 3},\n",
    "#     lower_bound=0.1,\n",
    "#     upper_bound=10.0,\n",
    "#     geostruct=pp_geostruct_k33,\n",
    "#     par_name_base=\"k33-pp-aq\",\n",
    "#     pargp=\"k33-pp-aq\",\n",
    "# )\n",
    "# df = pf.add_parameters(\n",
    "#     k33_files[3:],\n",
    "#     par_type=\"constant\",\n",
    "#     lower_bound=0.1,\n",
    "#     upper_bound=10.0,\n",
    "#     par_name_base=\"k33-cn-aq\",\n",
    "#     pargp=\"k33-cn-aq\",\n",
    "# )\n",
    "\n",
    "# pf.add_observations(\n",
    "#     k33_files[-1],\n",
    "#     obsgp=k33_files[-1].split(\".\")[1].replace(\"_\", \"-\"),\n",
    "#     prefix=k33_files[-1].split(\".\")[1].replace(\"_\", \"-\"),\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "And SS and sy (in layer 1 only):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_files = [f for f in os.listdir(pf.new_d) if f.startswith(\"sv.sto_ss\")]\n",
    "assert len(ss_files) == gwf.dis.nlay.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pf.add_parameters(\n",
    "    ss_files[:2],\n",
    "    par_type=\"pilotpoints\",\n",
    "    pp_options={\"pp_space\": 3},\n",
    "    lower_bound=0.1,\n",
    "    upper_bound=10.0,\n",
    "    geostruct=pp_geostruct_ss,\n",
    "    par_name_base=\"ss-pp-wt\",\n",
    "    pargp=\"ss-pp-wt\",\n",
    ")\n",
    "df = pf.add_parameters(\n",
    "    ss_files[:2],\n",
    "    par_type=\"constant\",\n",
    "    lower_bound=0.1,\n",
    "    upper_bound=10.0,\n",
    "    par_name_base=\"ss-cn-wt\",\n",
    "    pargp=\"ss-cn-wt\",\n",
    ")\n",
    "df = pf.add_parameters(\n",
    "    ss_files[2],\n",
    "    par_type=\"pilotpoints\",\n",
    "    pp_options={\"pp_space\": 3},\n",
    "    lower_bound=0.1,\n",
    "    upper_bound=10.0,\n",
    "    geostruct=pp_geostruct_ss,\n",
    "    par_name_base=\"ss-pp-conf\",\n",
    "    pargp=\"ss-pp-conf\",\n",
    ")\n",
    "df = pf.add_parameters(\n",
    "    ss_files[2],\n",
    "    par_type=\"constant\",\n",
    "    lower_bound=0.1,\n",
    "    upper_bound=10.0,\n",
    "    par_name_base=\"ss-cn-conf\",\n",
    "    pargp=\"ss-cn-conf\",\n",
    ")\n",
    "df = pf.add_parameters(\n",
    "    ss_files[3:],\n",
    "    par_type=\"pilotpoints\",\n",
    "    pp_options={\"pp_space\": 3},\n",
    "    lower_bound=0.1,\n",
    "    upper_bound=10.0,\n",
    "    geostruct=pp_geostruct_ss,\n",
    "    par_name_base=\"ss-pp-aq\",\n",
    "    pargp=\"ss-pp-aq\",\n",
    ")\n",
    "df = pf.add_parameters(\n",
    "    ss_files[3:],\n",
    "    par_type=\"constant\",\n",
    "    lower_bound=0.1,\n",
    "    upper_bound=10.0,\n",
    "    par_name_base=\"ss-cn-aq\",\n",
    "    pargp=\"ss-cn-aq\",\n",
    ")\n",
    "\n",
    "pf.add_observations(\n",
    "    ss_files[0],\n",
    "    obsgp=ss_files[0].split(\".\")[1].replace(\"_\", \"-\"),\n",
    "    prefix=ss_files[0].split(\".\")[1].replace(\"_\", \"-\"),\n",
    ")\n",
    "\n",
    "pf.add_observations(\n",
    "    ss_files[2],\n",
    "    obsgp=ss_files[2].split(\".\")[1].replace(\"_\", \"-\"),\n",
    "    prefix=ss_files[2].split(\".\")[1].replace(\"_\", \"-\"),\n",
    ")\n",
    "\n",
    "pf.add_observations(\n",
    "    ss_files[-1],\n",
    "    obsgp=ss_files[-1].split(\".\")[1].replace(\"_\", \"-\"),\n",
    "    prefix=ss_files[-1].split(\".\")[1].replace(\"_\", \"-\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "sy_files = [f for f in os.listdir(pf.new_d) if f.startswith(\"sv.sto_sy\")]\n",
    "assert len(sy_files) == gwf.dis.nlay.data\n",
    "sy_files.sort()\n",
    "sy_file = sy_files[0]\n",
    "assert \"layer1\" in sy_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pf.add_parameters(\n",
    "    sy_file,\n",
    "    par_type=\"pilotpoints\",\n",
    "    pp_options={\"pp_space\": 3},\n",
    "    lower_bound=0.6,\n",
    "    upper_bound=1.4,\n",
    "    geostruct=pp_geostruct_sy,\n",
    "    par_name_base=\"sy-pp-wt\",\n",
    "    pargp=\"sy-pp-wt\",\n",
    "    ult_ubound=1.0,\n",
    "    transform=\"none\",\n",
    ")\n",
    "df = pf.add_parameters(\n",
    "    sy_file,\n",
    "    par_type=\"constant\",\n",
    "    lower_bound=0.9,\n",
    "    upper_bound=1.1,\n",
    "    par_name_base=\"sy-cn-wt\",\n",
    "    pargp=\"sy-cn-wt\",\n",
    "    transform=\"none\",\n",
    ")\n",
    "pf.add_observations(\n",
    "    sy_file,\n",
    "    obsgp=sy_file.split(\".\")[1].replace(\"_\", \"-\"),\n",
    "    prefix=sy_file.split(\".\")[1].replace(\"_\", \"-\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "Set up some parameters for the pumping wells - we arent going to adjust these (dont we all have perfect historic water use data?!), but we will use them as decision variables later on..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "predwel_files = [\n",
    "    f\n",
    "    for f in os.listdir(pf.new_d)\n",
    "    if f.startswith(\"sv.prediction.well_stress_period_data_\")\n",
    "]\n",
    "assert len(predwel_files) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "Since the prediction well only has information for the predictive period, we can use its stress period/kper information to for other packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "kper_start_pred = 1000000\n",
    "for pwel_file in predwel_files:\n",
    "    kper = kper = int(pwel_file.split(\".\")[2].split(\"_\")[-1]) - 1\n",
    "    kper_min = min(kper_start_pred, kper)\n",
    "    pf.add_parameters(\n",
    "        pwel_file,\n",
    "        par_type=\"grid\",\n",
    "        index_cols=[0, 1, 2],\n",
    "        use_cols=[3],\n",
    "        upper_bound=3.0,\n",
    "        lower_bound=0.0,\n",
    "        pargp=\"predwel_kper:{0}\".format(kper),\n",
    "        par_name_base=\"predwel_kper:{0}\".format(kper),\n",
    "        transform=\"none\",\n",
    "        initial_value=1.0,\n",
    "        par_style=\"m\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "Now find any remaining wel/maw files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "wel_files = [f for f in os.listdir(pf.new_d) if f.startswith(\"sv.maw_perioddata\")]\n",
    "ismaw = True\n",
    "if len(wel_files) == 0:\n",
    "    wel_files = [f for f in os.listdir(pf.new_d) if f.startswith(\"sv.pwell.wel_\")]\n",
    "    ismaw = False\n",
    "assert len(wel_files) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {},
   "source": [
    "And add parameters for them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ismaw:\n",
    "    for wel_file in wel_files:\n",
    "        kper = int(wel_file.split(\".\")[1].split(\"_\")[-1]) - 1\n",
    "        if kper < kper_start_pred:\n",
    "            continue\n",
    "        if kper == 0:\n",
    "            continue\n",
    "        print(wel_file)\n",
    "        pf.add_parameters(\n",
    "            wel_file,\n",
    "            par_type=\"grid\",\n",
    "            par_style=\"m\",\n",
    "            par_name_base=\"welrate_kper:{0}\".format(kper),\n",
    "            pargp=\"welrate_kper:{0}\".format(kper),\n",
    "            mfile_skip=2,\n",
    "            index_cols=[0],\n",
    "            use_cols=[2],\n",
    "            mfile_fmt=\"free\",\n",
    "            upper_bound=3.0,\n",
    "            lower_bound=0.0,\n",
    "            transform=\"none\",\n",
    "        )\n",
    "else:\n",
    "    for wel_file in wel_files:\n",
    "        kper = int(wel_file.split(\".\")[2].split(\"_\")[-1]) - 1\n",
    "        if kper < kper_start_pred:\n",
    "            continue\n",
    "        pf.add_parameters(\n",
    "            wel_file,\n",
    "            par_type=\"grid\",\n",
    "            par_style=\"m\",\n",
    "            par_name_base=\"welrate_kper:{0}\".format(kper),\n",
    "            pargp=\"welrate_kper:{0}\".format(kper),\n",
    "            mfile_skip=2,\n",
    "            index_cols=[0, 1, 2],\n",
    "            use_cols=[3],\n",
    "            mfile_fmt=\"free\",\n",
    "            upper_bound=3.0,\n",
    "            lower_bound=0.0,\n",
    "            transform=\"none\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {},
   "source": [
    "Add some recharge parameters for the base model - this is to try to account for the uncertainty that has been introduced through simplification...if we are using uzf, then add some small uncertainties for precip/infilt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "rech_files = [\n",
    "    f for f in os.listdir(pf.new_d) if f.startswith(\"sv.rch_stress_period_data_\")\n",
    "]\n",
    "if len(rech_files) == 0:\n",
    "    uzf_pak_file = \"sv.uzf_packagedata.txt\"\n",
    "    if os.path.exists(os.path.join(pf.new_d, uzf_pak_file)):\n",
    "        uzf_files = [f for f in os.listdir(pf.new_d) if f.startswith(\"sv.uzf_period\")]\n",
    "        uzf_files.sort()\n",
    "        print(uzf_files)\n",
    "        assert len(uzf_files) == sim.tdis.nper.data\n",
    "        for uzf_file in uzf_files:\n",
    "            kper = int(uzf_file.split(\".\")[1].split(\"_\")[-1]) - 1\n",
    "            if kper >= kper_start_pred:  # dont add forecast parameters\n",
    "                continue\n",
    "            df = pf.add_parameters(\n",
    "                uzf_file,\n",
    "                par_type=\"constant\",\n",
    "                lower_bound=0.8,\n",
    "                upper_bound=1.2,\n",
    "                par_name_base=\"uzf-tcn_kper:{0}\".format(kper),\n",
    "                pargp=\"uzf-tcn_kper:{0}\".format(kper),\n",
    "                transform=None,\n",
    "                index_cols=[0],\n",
    "                use_cols=[1],\n",
    "                mfile_skip=0,\n",
    "            )\n",
    "    else:\n",
    "        raise Exception(\"didnt find any rech files or uzg package data file\")\n",
    "\n",
    "else:\n",
    "    assert len(rech_files) == sim.tdis.nper.data\n",
    "    rech_files.sort()\n",
    "    for rech_file in rech_files:\n",
    "        kper = int(rech_file.split(\".\")[1].split(\"_\")[-1]) - 1\n",
    "        if kper >= kper_start_pred:  # dont add forecast parameters\n",
    "            continue\n",
    "        df = pf.add_parameters(\n",
    "            rech_file,\n",
    "            par_type=\"constant\",\n",
    "            lower_bound=0.6,\n",
    "            upper_bound=1.4,\n",
    "            par_name_base=\"rech-tcn_kper:{0}\".format(kper),\n",
    "            pargp=\"rech-tcn_kper:{0}\".format(kper),\n",
    "            transform=None,\n",
    "            index_cols=[0, 1, 2],\n",
    "            use_cols=[3],\n",
    "            mfile_skip=0,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {},
   "source": [
    "Now build the interface and the control file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.build_pst(filename=\"pest.pst\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59",
   "metadata": {},
   "source": [
    "Check the `obsval` quantities in the \"* observation data\" section - what are those numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = pf.pst.observation_data\n",
    "obs.obsval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61",
   "metadata": {},
   "source": [
    "So if the `obsval` values are all the existing model output values, then if we run the model again just the same way, we should have a phi of zero - a great check!. Let's do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "pst = pf.pst\n",
    "pst.control_data.noptmax = 0\n",
    "pst.write(os.path.join(pf.new_d, \"pest.pst\"), version=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyemu.os_utils.run(\"pestpp-ies pest.pst\", cwd=pf.new_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.set_res(os.path.join(pf.new_d, \"pest.base.rei\"))\n",
    "pst.phi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65",
   "metadata": {},
   "source": [
    "assert pst.phi < 1.e7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66",
   "metadata": {},
   "source": [
    "now we need to \"fix\" the pumping well pars - those are for later when we do optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "par = pst.parameter_data\n",
    "\n",
    "wellpars = par.loc[par.parnme.str.contains(\"wel\"), :]\n",
    "assert len(wellpars) > 0\n",
    "par.loc[wellpars.parnme, \"partrans\"] = \"fixed\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {},
   "source": [
    "Now generate a Prior parameter ensemble (which the parameter bound and geostat info we passed to `PstFrom` above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "pe = pf.draw(num_reals=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70",
   "metadata": {},
   "source": [
    "We need to enforce parameter bounds on those realizations, save it and add an arg to the control file to tell ies to use it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "pe.enforce()\n",
    "pe.to_csv(os.path.join(pf.new_d, \"prior.csv\"))\n",
    "pst.pestpp_options[\"ies_par_en\"] = \"prior.csv\"\n",
    "pst.pestpp_options[\"ies_num_reals\"] = 30\n",
    "pst.control_data.noptmax = -1\n",
    "pst.write(os.path.join(pf.new_d, \"pest.pst\"), version=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72",
   "metadata": {},
   "source": [
    "Run the first realization in the ensemble:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.parameter_data.loc[pe.columns, \"parval1\"] = pe.iloc[0, :].values\n",
    "pst.control_data.noptmax = 0\n",
    "pst.write(os.path.join(pf.new_d, \"test.pst\"), version=2)\n",
    "pyemu.os_utils.run(\"pestpp-ies test.pst\", cwd=pf.new_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75",
   "metadata": {},
   "source": [
    "Extra:  run a small prior monte carlo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyemu.os_utils.start_workers(\n",
    "#     pf.new_d,\n",
    "#     \"pestpp-ies\",\n",
    "#     \"pest.pst\",\n",
    "#     worker_root=\".\",\n",
    "#     num_workers=10,\n",
    "#     master_dir=\"master_prior_mc\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
